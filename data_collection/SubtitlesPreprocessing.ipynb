{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5f602af9eb694c1590961ce88b42d10f",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Subtitle Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "08adaa9a76a640159c7a7381b090624a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Methodology: We first check that whether we can the folder name in our dataset as an IMDb ID of a movie.\n",
    "For each subtiitle that is matched with a movie, we then read each subtitle XML file using BeautifulSoup package and write clean sentences into a txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1968d7cc47184ffdb3195e44bdc0c112",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Here we show the resulting dataframes only. You can check the processed dataset at [here](https://drive.google.com/drive/folders/1FycaszmTdI2UjO06tgsg5nqvtpLG_z4s?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "71d26b5caaae4ecf8beefe6150080d95",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Libraries used and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "cell_id": "ed88339fe30148bdbfb4b89034743305",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 44,
    "execution_start": 1668810559850,
    "source_hash": "beeb9fc6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9de4967e8ae04be8888707269c7b2726",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "cell_id": "7c3ae293ae9d422cbe9e482c22ae30fe",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1668810127403,
    "source_hash": "86a872e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmu_path = Path('../data/raw/MovieSummaries/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "54e2dc885d5c4d56adbb2db28bea03bb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 799,
    "execution_start": 1668801692577,
    "source_hash": "71e6ef02",
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_names = [\n",
    "    'Wikipedia movie ID',\n",
    "    'Freebase movie ID',\n",
    "    'Movie name',\n",
    "    'Movie release date',\n",
    "    'Movie box office revenue',\n",
    "    'Movie runtime',\n",
    "    'Movie languages (Freebase ID:name tuples)',\n",
    "    'Movie countries (Freebase ID:name tuples)',\n",
    "    'Movie genres (Freebase ID:name tuples)'\n",
    "]\n",
    "\n",
    "df_movie = pd.read_csv(cmu_path.joinpath('movie.metadata.tsv'), delimiter='\\t', names=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9eb6a863bf5b4cd08fa35675ab33a999",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c659b987c78d4080a661f887bd069ff2",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '../data/raw/en/OpenSubtitles/xml/en/'\n",
    "OUTPUT_DIR = '..data/raw/subtitles/'\n",
    "WIKIDATA_PATH = '../data/preprocessed/wikipedia_ids.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f141248d993d4e5f99fe163557dd31f8",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ca964e3e0bdd4a3c84461858a4ea08f3",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xml2txt(xml_path: Union[Path, str], txt_path: Union[Path, str]) -> None:\n",
    "    '''\n",
    "    Opens an XML files using BeautifulSoup package, \n",
    "    reads every sentence by removing the tags \n",
    "    and writes every sentence to a new line into a txt file\n",
    "    '''\n",
    "    with open(xml_path, 'r', encoding='utf8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    Bs_data = BeautifulSoup(data, 'xml')\n",
    "    \n",
    "    text = []\n",
    "\n",
    "    sentences = Bs_data.find_all('s')\n",
    "    for sen in sentences:\n",
    "        words = sen.find_all('w')\n",
    "        sen = ' '.join([w.next_element for w in words])\n",
    "        text.append(sen+'\\n')\n",
    "        \n",
    "    with open(txt_path, 'w', encoding='utf8') as f:\n",
    "        f.writelines(text)\n",
    "        \n",
    "        \n",
    "def imdb_id_corrector(imdb_id:str) -> Union[str, None]:\n",
    "    if len(imdb_id) > 7:\n",
    "        # Folder names longer than 7 character do not seem to correspond to a correct IMDb ID\n",
    "        return None\n",
    "\n",
    "    additional_zeros = '0' * max(0, 7-len(imdb_id))\n",
    "    imdb_id = 'tt' + additional_zeros + imdb_id\n",
    "    \n",
    "    return imdb_id\n",
    "\n",
    "\n",
    "def check_imdb_id(test_id, imdb_id_list):\n",
    "    '''\n",
    "    Check if the folder name is in our dataset.\n",
    "    '''\n",
    "    for imdb_id in imdb_id_list:\n",
    "        if test_id in imdb_id:\n",
    "            return imdb_id\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c7a98dd657c2494e9c0142e903cc435e",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "Based on manual inspection, we observed that folder names longer than 7 \n",
    "character do not seem to correspond to a correct IMDb ID. Hence we discard all the folders with name length more than 7.\n",
    "Furthermore, IMDb ID follows the convention `tt*` where `*` is a squence of number with length either 7 or 8 [ref](https://en.wikipedia.org/wiki/Template:IMDb_title#:~:text=https%3A%2F%2Fwww.imdb.com,work%20if%20it%20is%20included).\n",
    "Hence we add leading zeros if the length of a folder name is less than 7 to obtain an appropriate ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e37ac176-b597-4d79-af2f-1e5977641fc6",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "We do not convert letters to lowercase or remove punctuations. These should be dealt with at the beginning of an NLP pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3f55d9a0b36d421fb7a52b4559f876b1",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "Do not process all them, only process if a candidate IMDb ID is contained in our movie dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6d8883fdea6b4a12ac496080802d2a92",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### Process subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "cell_id": "ae07675648ed4c19ae44dae7059757c9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1002,
    "execution_start": 1668808228117,
    "output_cleared": true,
    "source_hash": "dd042aa7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dir = Path(INPUT_DIR)\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "wikidata_path = Path(WIKIDATA_PATH)\n",
    "\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir()\n",
    "    \n",
    "\n",
    "wikidata = pd.read_csv(wikidata_path)\n",
    "imdb_id_list = wikidata['IMDb ID']\n",
    "imdb_id_list = imdb_ids[imdb_id_list.notna()]\n",
    "\n",
    "\n",
    "io_map  = {}\n",
    "\n",
    "# Find all the subtitles that matches a movie in our dataset\n",
    "for year_folder in tqdm(list(input_dir.iterdir())):\n",
    "    for movie_folder in tqdm(list(year_folder.iterdir()), leave=False):\n",
    "        sub_path = next(movie_folder.glob('*.xml'))\n",
    "\n",
    "        \n",
    "        movie_id = movie_folder.stem\n",
    "        imdb_id = check_imdb_id(movie_id, imdb_id_list)\n",
    "        if imdb_id is None:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        txt_path = output_dir.joinpath(imdb_id+'.txt')\n",
    "        \n",
    "        io_map[imdb_id] = [sub_path, txt_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ec33c502fda34d1db9417a74859ed079",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert subtitles\n",
    "for imdb_id, (subtitle_path, txt_path) in tqdm(io_map.items()):\n",
    "    xml2txt(subtitle_path, txt_path)"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [
   {
    "cellId": "e356300c249f4f5faaef512f8f0561f2",
    "msgId": "a22403e7-19fc-4f66-825b-dd45405df397",
    "sessionId": "bb1e1cf4-17eb-42c0-9db2-05a665f25dd5"
   }
  ],
  "deepnote_full_width": true,
  "deepnote_notebook_id": "f6921db6448145b780099346a578b7ca",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
